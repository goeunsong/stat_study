{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀식의 계수를 찾는 법 - OLS VS. SGD\n",
    "- 보스턴 집값 데이터 활용(RM VS Price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 필요한 라이브러리 import \n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LinearRegression 모델을 사용한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.46109164] -30.571032410898315\n",
      "y = 8.461092X + -30.571\n",
      "MSE: 36.517\n",
      "RMSE:  6.043\n",
      "R2:  0.602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# 데이터 수집\n",
    "boston = load_boston()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df =pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "X = pd.DataFrame(df['RM'])\n",
    "y = boston.target\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용, 20%는 검증용으로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\\\n",
    "                                                   random_state=1)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#모델 객체 생성\n",
    "reg = LinearRegression()\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SGDRegressor with hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.17510729] [-3.27733761]\n",
      "y = 4.175107X + -3.277\n",
      "MSE: 55.223\n",
      "RMSE:  7.431\n",
      "R2:  0.397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg= SGDRegressor()\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.92970862] [-1.45832261]\n",
      "y = 3.929709X + -1.458\n",
      "MSE: 57.083\n",
      "RMSE:  7.555\n",
      "R2:  0.377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg= SGDRegressor(max_iter=1000,eta0=0.001,learning_rate='constant')\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습률, 에폭\n",
    "#help(SGDRegressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.48581788] [-19.27301732]\n",
      "y = 6.485818X + -19.273\n",
      "MSE: 43.752\n",
      "RMSE:  6.615\n",
      "R2:  0.523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg= SGDRegressor(max_iter=1000,eta0=0.01,learning_rate='constant')\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SGDRegressor with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.83014279] [22.3749631]\n",
      "y = 5.830143X + 22.375\n",
      "MSE: 36.603\n",
      "RMSE:  6.05\n",
      "R2:  0.601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#표준화 scaling\n",
    "train_mean=np.mean(X_train,axis=0)\n",
    "train_std= np.std(X_train,axis=0)\n",
    "X_train=(X_train-train_mean)/train_std\n",
    "X_test = (X_test-train_mean)/train_std\n",
    "\n",
    "reg= SGDRegressor()\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SGDRegressor with standardscaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.88396585] [22.33251378]\n",
      "y = 5.883966X + 22.333\n",
      "MSE: 36.42\n",
      "RMSE:  6.035\n",
      "R2:  0.603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#표준화 scaling\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)  #기준 만들고 transform 도\n",
    "X_test=scaler.transform(X_test) # 만들어진 기준에 transform 만\n",
    "#y는 변환x\n",
    "\n",
    "reg= SGDRegressor()\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
